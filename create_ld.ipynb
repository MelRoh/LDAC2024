{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39355076",
   "metadata": {},
   "source": [
    "**Lets create some code üí™üîëüåê**\n",
    "\n",
    "Read data and add to dataframe\n",
    "\n",
    "Shafts-data comes from htlm file of http://www.zechenkarte.de/wiki/index.php?title=Gesamtkarte\n",
    "\n",
    "Mine data comes from the xlsx file, where the data starts from line 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6fcbfd8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fuzz in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (0.1.1)\n",
      "Requirement already satisfied: fuzzywuzzy in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (0.18.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (2.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement as (from versions: none)\n",
      "ERROR: No matching distribution found for as\n",
      "ERROR: Could not find a version that satisfies the requirement json (from versions: none)\n",
      "ERROR: No matching distribution found for json\n",
      "ERROR: Could not find a version that satisfies the requirement csv (from versions: none)\n",
      "ERROR: No matching distribution found for csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rdflib in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (7.0.0)\n",
      "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (from rdflib) (0.6.1)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (from rdflib) (3.1.2)\n",
      "Requirement already satisfied: six in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (from isodate<0.7.0,>=0.6.0->rdflib) (1.16.0)\n",
      "Requirement already satisfied: folium in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (0.16.0)\n",
      "Requirement already satisfied: branca>=0.6.0 in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (from folium) (0.7.2)\n",
      "Requirement already satisfied: jinja2>=2.9 in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (from folium) (3.1.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (from folium) (1.26.4)\n",
      "Requirement already satisfied: requests in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (from folium) (2.32.3)\n",
      "Requirement already satisfied: xyzservices in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (from folium) (2024.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (from jinja2>=2.9->folium) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (from requests->folium) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (from requests->folium) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (from requests->folium) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (from requests->folium) (2024.6.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (3.9.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (from matplotlib) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: mapclassify in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (2.6.1)\n",
      "Requirement already satisfied: networkx>=2.7 in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (from mapclassify) (3.3)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (from mapclassify) (1.26.4)\n",
      "Requirement already satisfied: pandas!=1.5.0,>=1.4 in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (from mapclassify) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn>=1.0 in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (from mapclassify) (1.5.0)\n",
      "Requirement already satisfied: scipy>=1.8 in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (from mapclassify) (1.13.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (from pandas!=1.5.0,>=1.4->mapclassify) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (from pandas!=1.5.0,>=1.4->mapclassify) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (from pandas!=1.5.0,>=1.4->mapclassify) (2024.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (from scikit-learn>=1.0->mapclassify) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (from scikit-learn>=1.0->mapclassify) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rohne\\documents\\ldac\\ldac\\lib\\site-packages (from python-dateutil>=2.8.2->pandas!=1.5.0,>=1.4->mapclassify) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install fuzz\n",
    "!pip install fuzzywuzzy\n",
    "!pip install pandas as pd\n",
    "!pip install json\n",
    "!pip install csv\n",
    "!pip install rdflib\n",
    "!pip install folium\n",
    "!pip install matplotlib\n",
    "!pip install mapclassify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e15f274c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl\n",
    "from fuzzywuzzy import fuzz\n",
    "from pandas import json_normalize\n",
    "import json\n",
    "\n",
    "\n",
    "from rdflib import Graph, Literal, Namespace, RDF, URIRef\n",
    "from rdflib.namespace import GEO, XSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b173ca88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data form the excel sheet\n",
    "\n",
    "file_path = 'C:/Users/rohne/Documents/LDAC/LDAC2024/data/Steinkohlenzechen_NRW.xlsx'  # Adjust the path as needed\n",
    "excel_file = pd.ExcelFile(file_path)\n",
    "\n",
    "# Iterate through all sheet names\n",
    "#sheets_data ={}\n",
    "dataframe = []\n",
    "for sheet_name in excel_file.sheet_names:\n",
    "    # Read the sheet starting from the 5th line (index 4) with the 5th line as header (index 4)\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name, header=4)\n",
    "    df['year']=sheet_name\n",
    "    dataframe.append(df)\n",
    "\n",
    "mines = pd.concat(dataframe, ignore_index=True)\n",
    "\n",
    "    # Store the DataFrame in the dictionary\n",
    "    #sheets_data[sheet_name] = shafts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7fb9d070",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data from the html file\n",
    "\n",
    "shafts_path = 'Mines_all_small.json'\n",
    "with open(shafts_path) as f:\n",
    "    data = json.load(f)\n",
    "shafts = json_normalize(data['locations'])\n",
    "\n",
    "# print(mines.Mine)\n",
    "# print(shafts.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "93ffe7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preparation, Add additional Table for fuzzy \n",
    "shafts['title_fuzzy']=shafts['title']\n",
    "shafts['title_fuzzy'] = shafts['title_fuzzy'].str.replace(' Schacht', '', case=False)\n",
    "shafts['title_fuzzy'] = shafts['title_fuzzy'].str.strip()\n",
    "\n",
    "mines['title_fuzzy']=mines['Name des Bergwerks']\n",
    "words_to_remove = ['Gewerkschaft', 'Zeche', 'ver.', 'Bergwerk', 'Bergbau', 'Aktien', 'Gesellschaft']\n",
    "pattern = '|'.join(words_to_remove)\n",
    "mines['title_fuzzy'] = mines['title_fuzzy'].str.replace(pattern, '', case=False, regex=True)\n",
    "mines['title_fuzzy'] = mines['title_fuzzy'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "767720bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute similarity and group mines\n",
    "def group_similar_titles(mines, threshold=85):\n",
    "    # List to store group indices\n",
    "    groups = [-1] * len(mines)\n",
    "    group_id = 0\n",
    "    \n",
    "    # Iterate over each title to compare it with others\n",
    "    for i in range(len(mines)):\n",
    "        if groups[i] == -1:  # If not already assigned to a group\n",
    "            groups[i] = group_id\n",
    "            for j in range(i + 1, len(mines)):\n",
    "                if groups[j] == -1:  # If not already assigned to a group\n",
    "                    similarity_score = fuzz.ratio(str(mines.loc[i, 'title_fuzzy']+ ' '+mines.loc[i,'Ort']),str(mines.loc[j, 'title_fuzzy']+ ' '+mines.loc[j,'Ort']))\n",
    "                \n",
    "                    if similarity_score >= threshold:\n",
    "                        groups[j] = group_id\n",
    "                        #print(mines.loc[i, 'title_fuzzy'],',', mines.loc[j, 'title_fuzzy'],'->', similarity_score)\n",
    "            group_id += 1\n",
    "    \n",
    "    return groups\n",
    "\n",
    "# Apply the function to group similar titles\n",
    "mines['mine_group'] = group_similar_titles(mines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4aa7d1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to concatenate unique values while handling NaNs\n",
    "def concat_unique(series):\n",
    "    unique_values = series.dropna().unique()  # Drop NaNs and get unique values\n",
    "    return ', '.join(unique_values) if unique_values.size > 0 else None\n",
    "\n",
    "mines_only = mines.copy()\n",
    "mines_only = mines_only.groupby('mine_group').agg(\n",
    "    title = ('Name des Bergwerks', 'first')\n",
    "    ,ort = ('Ort','first')\n",
    "    ,revier = ('Revier','first')\n",
    "    ,title_fuzzy = ('title_fuzzy','first')\n",
    "    ,weitere_informationen = ('weitere Informationen',concat_unique)  # Additional information\n",
    "\n",
    "    #company_form =('Unternehmensform','first')\n",
    "    ).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e52e2b1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "50651730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches found: 1018\n"
     ]
    }
   ],
   "source": [
    "# Define a function to compute string similarity\n",
    "def compute_similarity(string1, string2):\n",
    "    return fuzz.ratio(string1, string2)  # You can use other similarity metrics here\n",
    "\n",
    "matches = []\n",
    "for index1, row1 in mines_only.iterrows():\n",
    "    for index2, row2 in shafts.iterrows():\n",
    "        similarity_score = compute_similarity(row1['title_fuzzy'], row2['title_fuzzy']) \n",
    "        if similarity_score >= 60:  # Set a threshold for similarity\n",
    "            matches.append((index1, index2, similarity_score))\n",
    "\n",
    "matches_df = pd.DataFrame(matches, columns=['index_mines_group', 'index_shafts', 'similarity_score'])\n",
    "           \n",
    "# Output matches\n",
    "if len(matches) == 0:\n",
    "    print(\"No matches found.\")\n",
    "else:\n",
    "    print(\"Matches found:\", len(matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "79bad911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N6e5d8440326441d38faaa92b56faafcb (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create ttl file for mines \n",
    "#\n",
    "EX = Namespace(\"http://example.org/\")\n",
    "#GEO = Namespace(\"http://www.geonames.org/ontology#\")\n",
    "SCHEMA = Namespace(\"http://schema.org/\")\n",
    "GEO = Namespace(\"http://www.opengis.net/ont/geosparql#\")\n",
    "\n",
    "# Create an RDF graph\n",
    "g = Graph()\n",
    "g.remove((None, None, None))\n",
    "g.bind(\"ex\", EX)\n",
    "g.bind(\"geo\", GEO)\n",
    "g.bind(\"schema\", SCHEMA)\n",
    "\n",
    "for index, row in mines_only.iterrows():\n",
    "\n",
    "    title = row.title\n",
    "    ort = row.ort\n",
    "    revier = row.revier\n",
    "    UID_mine = row.mine_group\n",
    "    weitere_informationen = row.weitere_informationen\n",
    "\n",
    "    mine_uri = URIRef(EX + \"mine/\"+ str(UID_mine))\n",
    "    \n",
    "    g.add((mine_uri, RDF.type, EX.Mine))\n",
    "    g.add((mine_uri, EX.name, Literal(title)))\n",
    "    g.add((mine_uri, GEO.location, Literal(ort)))\n",
    "    g.add((mine_uri, SCHEMA.Place, Literal(revier)))\n",
    "    g.add((mine_uri, EX.info, Literal(weitere_informationen)))\n",
    "    \n",
    "ttl_file = 'mines.ttl'\n",
    "g.serialize(destination=ttl_file, format='turtle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a4fc9e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "materials = mines.copy()\n",
    "materials['Koksproduktion'] = materials['Koksproduktion in Tonnen (1906)'].fillna(materials['Koksproduktion in Tonnen'])\n",
    "materials['F√∂rderung'] = materials['F√∂rderung in Tonnen (1906)'].fillna(materials['F√∂rderung in Tonnen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "102eda53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N6eb50e93b1fc47b69f4f269ac665fd5c (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Materials\n",
    "EX = Namespace(\"http://example.org/\")\n",
    "GEO = Namespace(\"http://www.opengis.net/ont/geosparql#\")\n",
    "SCHEMA = Namespace(\"http://schema.org/\")\n",
    "\n",
    "# Create an RDF graph\n",
    "g = Graph()\n",
    "g.remove((None, None, None))\n",
    "g.bind(\"ex\", EX)\n",
    "g.bind(\"schema\", SCHEMA)\n",
    "\n",
    "for index, row in materials.iterrows():\n",
    "    title = row['abgebauter Rohstoff']  # Material name\n",
    "    #ort = row['Ort']  # Location\n",
    "    #revier = row['Revier']  # Mining district\n",
    "    unternehmensform = row['Unternehmensform']  # Company type\n",
    "    syndikatsbeteiligung = row['Syndikatsbeteiligung']  # Syndicate participation\n",
    "    #foerderung_1906 = row['F√∂rderung in Tonnen (1906)']  # Production in tons (1906)\n",
    "    kohlensorte = row['Kohlensorte']  # Coal type\n",
    "    kokssorte = row['Kokssorte']  # Coke type\n",
    "    #koksproduktion_1906 = row['Koksproduktion in Tonnen (1906)']  # Coke production in tons (1906)\n",
    "    sonstige_nebenprodukte = row['sonstige Nebenprodukte']  # Other by-products\n",
    "    #seite = row['Seite']  # Page number\n",
    "    year = row['year']  # Year\n",
    "    foerderung = row['F√∂rderung']  # Production in tons\n",
    "    koksproduktion = row['Koksproduktion']  # Coke production in tons\n",
    "    UID_mine = row.mine_group\n",
    "    mine_uri = URIRef(EX + \"mine/\"+ str(UID_mine))\n",
    "\n",
    "    # Create URI for the material\n",
    "    material_uri = URIRef(EX +\"material/\" + str(row['mine_group']) + \"/\" + str(row['year']) ) # Using material name as URI, adjust as needed\n",
    "\n",
    "    # Add triples to the RDF graph\n",
    "    g.add((material_uri, RDF.type, EX.Material))\n",
    "    g.add((material_uri, EX.name, Literal(title)))\n",
    "    #g.add((material_uri, GEO.name, Literal(ort)))\n",
    "    #g.add((material_uri, SCHEMA.Place, Literal(revier)))\n",
    "    g.add((material_uri, EX.Unternehmensform, Literal(unternehmensform)))\n",
    "    g.add((material_uri, EX.Syndikatsbeteiligung, Literal(syndikatsbeteiligung)))\n",
    "    g.add((material_uri, EX.Kohlensorte, Literal(kohlensorte)))\n",
    "    g.add((material_uri, EX.Kokssorte, Literal(kokssorte)))\n",
    "    g.add((material_uri, EX.sonstige_Nebenprodukte, Literal(sonstige_nebenprodukte)))\n",
    "    #g.add((material_uri, EX.Seite, Literal(seite)))\n",
    "    g.add((material_uri, SCHEMA.year, Literal(year,datatype=XSD.gYear)))\n",
    "    g.add((material_uri, EX.foerderung, Literal(foerderung)))\n",
    "    g.add((material_uri, EX.koksproduktion, Literal(koksproduktion)))\n",
    "    g.add((mine_uri, EX.hasMaterial, material_uri))\n",
    "    g.add((material_uri, EX.hasMine, mine_uri))\n",
    "\n",
    "ttl_file = 'mines_materials.ttl'\n",
    "g.serialize(destination=ttl_file, format='turtle')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "074fb022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N6bb6351328d641388d0c46dd5fdbcdb1 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create ttl file for shafts\n",
    "# Define namespaces\n",
    "EX = Namespace(\"http://example.org/\")\n",
    "GEO = Namespace(\"http://www.opengis.net/ont/geosparql#\")\n",
    "\n",
    "# Create an RDF graph\n",
    "g = Graph()\n",
    "g.remove((None, None, None))\n",
    "g.bind(\"ex\", EX)\n",
    "g.bind(\"geo\", GEO)\n",
    "\n",
    "# Process each entry in the JSON data\n",
    "for index, row in shafts.iterrows():\n",
    "\n",
    "    title_item = row.title\n",
    "    latitude = row.lat\n",
    "    longitude = row.lon\n",
    "    \n",
    "    # Create URI for the title and geometry\n",
    "    title_uri = EX[\"http://www.zechenkarte.de/wiki/index.php?title=\" + title_item.replace(\" \", \"_\")]\n",
    "    geom_uri = EX[title_item.replace(\" \", \"_\") + \"Geom\"]\n",
    "    \n",
    "    # Add RDF triples to the graph\n",
    "    g.add((title_uri, RDF.type, EX.Schacht))\n",
    "    g.add((title_uri, EX.name, Literal(title_item)))\n",
    "    g.add((title_uri, GEO.hasGeometry, geom_uri))\n",
    "    \n",
    "    g.add((geom_uri, RDF.type, GEO.Geometry))\n",
    "    g.add((geom_uri, GEO.asWKT, Literal(f\"POINT({longitude} {latitude})\", datatype=GEO.wktLiteral)))\n",
    "\n",
    "    matches_filtered = matches_df[matches_df.index_shafts == index]\n",
    "    if not matches_filtered.empty:\n",
    "        for _, match_row in matches_filtered.iterrows(): \n",
    "            UID_mine = match_row[\"index_mines_group\"]\n",
    "        \n",
    "            mine_uri = URIRef(EX + \"mine/\"+ str(UID_mine))\n",
    "\n",
    "\n",
    "            g.add((mine_uri, EX.hasShafts, title_uri))\n",
    "            g.add((title_uri, EX.hasMine, mine_uri))\n",
    "\n",
    "# Serialize the graph to a TTL file\n",
    "g.serialize(destination='shafts.ttl', format='turtle')\n",
    "\n",
    "#print(\"TTL file created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570fe4c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b5e929fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "##ToDo Add the queries \n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from rdflib import Graph, Namespace\n",
    "from rdflib.namespace import RDF, GEO\n",
    "\n",
    "# Define namespaces\n",
    "EX = Namespace(\"http://example.org/\")\n",
    "GEO = Namespace(\"http://www.opengis.net/ont/geosparql#\")\n",
    "\n",
    "# Load the RDF graph from the TTL file\n",
    "g = Graph()\n",
    "g.parse(\"shafts.ttl\", format=\"turtle\")\n",
    "#g.parse(\"mines.ttl\", format=\"turtle\")\n",
    "\n",
    "# Define the SPARQL query\n",
    "query = \"\"\"\n",
    "PREFIX ex: <http://example.org/>\n",
    "PREFIX geo: <http://www.opengis.net/ont/geosparql#>\n",
    "\n",
    "SELECT ?schacht ?name ?wkt\n",
    "WHERE {\n",
    "  ?schacht a ex:Schacht ;\n",
    "           ex:name ?name ;\n",
    "           ex:\n",
    "           geo:hasGeometry ?geom .\n",
    "  ?geom geo:asWKT ?wkt .\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "results = g.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "411e44fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<rdflib.plugins.sparql.processor.SPARQLResult object at 0x0000021695522E90>\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8bcdef86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohne\\AppData\\Local\\Temp\\ipykernel_39400\\3579149396.py:17: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  gdf.to_file(\"schachts.shp\", driver='ESRI Shapefile')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extraction and shapefile creation complete.\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for GeoDataFrame\n",
    "data = []\n",
    "for row in results:\n",
    "    schacht_uri = str(row.schacht)\n",
    "    name = str(row.name).strip()\n",
    "    wkt = str(row.wkt)\n",
    "    \n",
    "    # Convert WKT to shapely geometry\n",
    "    geometry = Point(float(wkt.split('(')[1].split()[0]), float(wkt.split('(')[1].split()[1][:-1]))\n",
    "    \n",
    "    data.append({\"schacht_uri\": schacht_uri, \"name\": name, \"geometry\": geometry})\n",
    "\n",
    "# Create a GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(data, geometry=\"geometry\")\n",
    "\n",
    "# Save the GeoDataFrame to a shapefile\n",
    "gdf.to_file(\"schachts.shp\", driver='ESRI Shapefile')\n",
    "gdf.to_file('schachts.geojson', driver='GeoJSON')  \n",
    "\n",
    "print(\"Data extraction and shapefile creation complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5861e4f2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b05eac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohne\\AppData\\Local\\Temp\\ipykernel_29560\\923309337.py:25: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  gdf.to_file('Results1_Zeche-Shaft-point_gdf.shp')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from shapely import wkt\n",
    "\n",
    "# Read the specified sheet (Sheet 2) from the Excel file into a DataFrame\n",
    "df = pd.read_excel(\"Result1_Zeche-Shaft-point.xlsx\", sheet_name='Sheet2')  # You can also use sheet_name=1 to refer to the second sheet by index\n",
    "\n",
    "df['POINT'] = df['POINT'].str.strip('\"')\n",
    "\n",
    "# Convert the 'POINT' column from string to Shapely Point objects\n",
    "df['geometry'] = df['POINT'].apply(wkt.loads)  # Replace 'POINT' with the actual column name if different\n",
    "\n",
    "# Create a GeoDataFrame from the DataFrame\n",
    "gdf = gpd.GeoDataFrame(df, geometry='geometry')\n",
    "\n",
    "# Set the coordinate reference system (CRS) to WGS84 (EPSG:4326)\n",
    "gdf.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "# Use the explore method to visualize the data\n",
    "# Color the points based on the 'Footprint' column (replace 'Footprint' with the actual column name)\n",
    "#gdf.explore(column='Zeche', cmap='viridis', legend=True)\n",
    "gdf.explore()\n",
    "# Set the coordinate reference system (CRS) to\n",
    "gdf.to_file('Results1_Zeche-Shaft-point_gdf.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e03981ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Zeche_gdf_data = gpd.read_file('Zeche_polygon.geojson')\n",
    "#geom = str(Zeche_gdf.geometry)\n",
    "Zeche_data = pd.read_excel(\"Result2_Zeche_Year_Material.xlsx\")\n",
    "\n",
    "# Extract the geometry\n",
    "geometry = Zeche_gdf_data.geometry.iloc[0]\n",
    "\n",
    "# Create a new DataFrame with the desired data from Zeche_data\n",
    "new_data = Zeche_data.copy()\n",
    "\n",
    "# Assign the geometry to each row in the new DataFrame\n",
    "new_data['geometry'] = geometry\n",
    "\n",
    "# Create a new GeoDataFrame with the combined data and geometry\n",
    "Zeche_gdf = gpd.GeoDataFrame(new_data, geometry='geometry')\n",
    "\n",
    "# Now combined_gdf contains both the data from Zeche_data and the geometry from Zeche_gdf\n",
    "Zeche_gdf.to_file('Zeche_gdf.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "868edc46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coal</th>\n",
       "      <th>year</th>\n",
       "      <th>CoalName</th>\n",
       "      <th>CoalWeight</th>\n",
       "      <th>coke</th>\n",
       "      <th>CokeMaterialName</th>\n",
       "      <th>CokeWeight</th>\n",
       "      <th>materialinst</th>\n",
       "      <th>raw</th>\n",
       "      <th>RawMaterialName</th>\n",
       "      <th>RawMaterialWeight</th>\n",
       "      <th>Year</th>\n",
       "      <th>Zeche</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_:bc_0_n3-37</td>\n",
       "      <td>1895</td>\n",
       "      <td>\"Fett-, Mager- und Esskohlen\"</td>\n",
       "      <td>219950</td>\n",
       "      <td>_:bc_0_n3-38</td>\n",
       "      <td>\"Hochofen- und Gie√üereikoks\"</td>\n",
       "      <td>\"82300\"</td>\n",
       "      <td>&lt;http://linkedbuildingdata.net/mine/MaterialSe...</td>\n",
       "      <td>_:bc_0_n3-36</td>\n",
       "      <td>\"Steinkohle\"</td>\n",
       "      <td>\"0\"</td>\n",
       "      <td>&lt;https://w3id.org/cmo#1895&gt;</td>\n",
       "      <td>&lt;http://linkedbuildingdata.net/mine/Maria-Anna...</td>\n",
       "      <td>MULTIPOLYGON (((7.15147 51.44793, 7.15659 51.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_:bc_0_n3-40</td>\n",
       "      <td>1990</td>\n",
       "      <td>\"Fett-, Mager- und Esskohlen\"</td>\n",
       "      <td>228576</td>\n",
       "      <td>_:bc_0_n3-41</td>\n",
       "      <td>\"Hochofen- und Gie√üereikoks\"</td>\n",
       "      <td>\"69142\"</td>\n",
       "      <td>&lt;http://linkedbuildingdata.net/mine/MaterialSe...</td>\n",
       "      <td>_:bc_0_n3-39</td>\n",
       "      <td>\"Steinkohle\"</td>\n",
       "      <td>\"0\"</td>\n",
       "      <td>&lt;https://w3id.org/cmo#1990&gt;</td>\n",
       "      <td>&lt;http://linkedbuildingdata.net/mine/Maria-Anna...</td>\n",
       "      <td>MULTIPOLYGON (((7.15147 51.44793, 7.15659 51.4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           coal  year                       CoalName  CoalWeight  \\\n",
       "0  _:bc_0_n3-37  1895  \"Fett-, Mager- und Esskohlen\"      219950   \n",
       "1  _:bc_0_n3-40  1990  \"Fett-, Mager- und Esskohlen\"      228576   \n",
       "\n",
       "           coke              CokeMaterialName CokeWeight  \\\n",
       "0  _:bc_0_n3-38  \"Hochofen- und Gie√üereikoks\"    \"82300\"   \n",
       "1  _:bc_0_n3-41  \"Hochofen- und Gie√üereikoks\"    \"69142\"   \n",
       "\n",
       "                                        materialinst           raw  \\\n",
       "0  <http://linkedbuildingdata.net/mine/MaterialSe...  _:bc_0_n3-36   \n",
       "1  <http://linkedbuildingdata.net/mine/MaterialSe...  _:bc_0_n3-39   \n",
       "\n",
       "  RawMaterialName RawMaterialWeight                         Year  \\\n",
       "0    \"Steinkohle\"               \"0\"  <https://w3id.org/cmo#1895>   \n",
       "1    \"Steinkohle\"               \"0\"  <https://w3id.org/cmo#1990>   \n",
       "\n",
       "                                               Zeche  \\\n",
       "0  <http://linkedbuildingdata.net/mine/Maria-Anna...   \n",
       "1  <http://linkedbuildingdata.net/mine/Maria-Anna...   \n",
       "\n",
       "                                            geometry  \n",
       "0  MULTIPOLYGON (((7.15147 51.44793, 7.15659 51.4...  \n",
       "1  MULTIPOLYGON (((7.15147 51.44793, 7.15659 51.4...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zeche_gdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
